{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6h5Fan0GWU/7J1mote8dB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/regalleo/regalleo/blob/main/Untitled12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iS3OM8sHQg2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da1f7e34-4a39-42f0-d74a-3fab0cdb688c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sales RDD Sample:\n",
            "[['T001', 'C001', 'P001', '75000', '2025-08-25', 'Credit Card', 'Bangalore'], ['T002', 'C002', 'P002', '45000', '2025-08-20', 'UPI', 'Delhi'], ['T003', 'C003', 'P003', '60000', '2025-08-18', 'Debit Card', 'Mumbai'], ['T004', 'C004', 'P004', '30000', '2025-08-15', 'Net Banking', 'Chennai'], ['T005', 'C005', 'P005', '2500', '2025-08-10', 'COD', 'Hyderabad']]\n",
            "\n",
            "Employees RDD Sample:\n",
            "[['E001', 'Raj Shekhar', 'Engineering', '95000', '2020-05-10', 'Bangalore'], ['E002', 'Ananya Sharma', 'HR', '50000', '2021-01-12', 'Delhi'], ['E003', 'Rahul Verma', 'Finance', '85000', '2019-07-19', 'Mumbai'], ['E004', 'Priya Nair', 'Engineering', '105000', '2018-03-15', 'Chennai'], ['E005', 'Sneha Kapoor', 'Marketing', '60000', '2022-09-05', 'Hyderabad']]\n",
            "\n",
            "Movies RDD Sample:\n",
            "[['U001', 'M001', '4', '2025-08-10 10:15:00', 'Action'], ['U002', 'M002', '5', '2025-08-12 15:30:00', 'Drama'], ['U003', 'M003', '2', '2025-08-13 18:45:00', 'Comedy'], ['U001', 'M004', '3', '2025-08-14 20:00:00', 'Drama'], ['U002', 'M001', '4', '2025-08-15 11:20:00', 'Action']]\n"
          ]
        }
      ],
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Spark Context & Session\n",
        "conf = SparkConf().setAppName(\"RDD_Practice\").setMaster(\"local[*]\")\n",
        "sc = SparkContext.getOrCreate(conf=conf)\n",
        "spark = SparkSession.builder.appName(\"RDD_Practice\").getOrCreate()\n",
        "\n",
        "# Load datasets into RDDs\n",
        "r1 = sc.textFile(\"sales.csv\")\n",
        "r2 = sc.textFile(\"employees.csv\")\n",
        "r3 = sc.textFile(\"movies.csv\")\n",
        "\n",
        "# Remove headers and split by comma\n",
        "h1 = r1.first()\n",
        "r1 = r1.filter(lambda x: x != h1).map(lambda x: x.split(\",\"))\n",
        "\n",
        "h2 = r2.first()\n",
        "r2 = r2.filter(lambda x: x != h2).map(lambda x: x.split(\",\"))\n",
        "\n",
        "h3 = r3.first()\n",
        "r3 = r3.filter(lambda x: x != h3).map(lambda x: x.split(\",\"))\n",
        "\n",
        "# ✅ Check first 5 rows from each dataset\n",
        "print(\"Sales RDD Sample:\")\n",
        "print(r1.take(5))\n",
        "\n",
        "print(\"\\nEmployees RDD Sample:\")\n",
        "print(r2.take(5))\n",
        "\n",
        "print(\"\\nMovies RDD Sample:\")\n",
        "print(r3.take(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📝 20 Mixed RDD Questions (Sales + Employees + Movies)\n",
        "# 🔹 Cross-Dataset Analytics\n",
        "# Join sales and employees by city → find total revenue per city per department.\n",
        "amt_city_and_dept_loc_revenue_percity_perdept=r1.map(lambda x:(x[6],int(x[3]))).join(r2.map(lambda x:(x[5],x[2]))).map(lambda x:((x[0],x[1][1]),x[1][0])).reduceByKey(lambda x,y:x+y)\n",
        "for i in amt_city_and_dept_loc_revenue_percity_perdept.collect():\n",
        "  print(i)\n",
        "\n",
        "# Find the employee with the highest salary in the city with maximum total sales revenue.\n",
        "max_city = r1.map(lambda x: (x[6], int(x[3]))).reduceByKey(lambda a, b: a + b).max(lambda x: x[1])[0]\n",
        "print(max_city)\n",
        "\n",
        "highest_paid = r2.filter(lambda x: x[5] == max_city).map(lambda x: (x[1], int(x[3]))).max(lambda x: x[1])\n",
        "print(highest_paid)\n",
        "\n",
        "# For each city, compute:\n",
        "# Total employees\n",
        "j2=r2.map(lambda x:(x[5],1)).reduceByKey(lambda a,b:a+b).sortBy(lambda x:x[0])\n",
        "print(j2.collect())\n",
        "\n",
        "# Total sales revenue\n",
        "j3=r1.map(lambda x:int(x[3])).sum()\n",
        "print(j3)\n",
        "# Average revenue per employee.\n",
        "j3=r1.map(lambda x:int(x[3])).sum()\n",
        "j4=r2.count()\n",
        "j5=j3/j4\n",
        "print(j5)\n",
        "# Join employees and movies → check if any employee’s join year = any movie’s release year, list matches.\n",
        "join_year_and_empname=r2.map(lambda x: (int(x[4].split(\"-\")[0]),x[1]))\n",
        "movie_relDate_and_movieID=r3.map(lambda x:(int(x[3].split(\"-\")[0]),x[1]))\n",
        "j6=join_year_and_empname.join(movie_relDate_and_movieID)\n",
        "print(j6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikWEeI98U3bC",
        "outputId": "54b578b6-5cfd-4231-acfa-fba9e4fd35e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(('Delhi', 'HR'), 48500)\n",
            "(('Mumbai', 'Engineering'), 105000)\n",
            "(('Bangalore', 'Engineering'), 76200)\n",
            "(('Mumbai', 'Finance'), 105000)\n",
            "(('Hyderabad', 'Marketing'), 2500)\n",
            "(('Chennai', 'Engineering'), 30000)\n",
            "(('Bangalore', 'Finance'), 76200)\n",
            "Mumbai\n",
            "('Kavya Iyer', 98000)\n",
            "[('Bangalore', 2), ('Chennai', 1), ('Delhi', 1), ('Hyderabad', 1), ('Mumbai', 2)]\n",
            "262200\n",
            "37457.142857142855\n",
            "PythonRDD[60] at RDD at PythonRDD.scala:53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 Moderate-Level Questions:datasets required :customers_rdd.csv,orders_rdd.csv,products_rdd.csv\n",
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Spark Context & Session\n",
        "conf = SparkConf().setAppName(\"RDD_Practice\").setMaster(\"local[*]\")\n",
        "sc = SparkContext.getOrCreate(conf=conf)\n",
        "spark = SparkSession.builder.appName(\"RDD_Practice\").getOrCreate()\n",
        "\n",
        "# Load datasets into RDDs\n",
        "r1 = sc.textFile(\"customers_rdd.csv\")\n",
        "r2 = sc.textFile(\"orders_rdd.csv\")\n",
        "r3 = sc.textFile(\"products_rdd.csv\")\n",
        "\n",
        "# Remove headers and split by comma\n",
        "h1 = r1.first()\n",
        "r1 = r1.filter(lambda x: x != h1).map(lambda x: x.split(\",\"))\n",
        "\n",
        "h2 = r2.first()\n",
        "r2 = r2.filter(lambda x: x != h2).map(lambda x: x.split(\",\"))\n",
        "\n",
        "h3 = r3.first()\n",
        "r3 = r3.filter(lambda x: x != h3).map(lambda x: x.split(\",\"))\n",
        "\n",
        "# # ✅ Check first 5 rows from each dataset\n",
        "# print(\"Customers RDD Sample:\")\n",
        "# print(r1.take(5))\n",
        "\n",
        "# print(\"\\nOrders RDD Sample:\")\n",
        "# print(r2.take(5))\n",
        "\n",
        "# print(\"\\nProducts RDD Sample:\")\n",
        "# print(r3.take(5))\n",
        "\n",
        "# 1. Ranking & Aggregation\n",
        "# # Find the top 2 customers by total spending.\n",
        "# # Example: r1 = [\"O001,C001,P001,2,2025-08-20\", ...]\n",
        "# top2 = (\n",
        "#     r1.map(lambda x: (x.split(\",\")[1], int(x.split(\",\")[3])))   # (customer_id, amount)\n",
        "#       .reduceByKey(lambda a, b: a + b)                         # total spending per customer\n",
        "#       .join(r2.map(lambda x: (x.split(\",\")[0], x.split(\",\")[1])))  # join with customer_id → name\n",
        "#       .map(lambda x: (x[1][1], x[1][0]))                       # (customer_name, total_spent)\n",
        "#       .takeOrdered(2, key=lambda x: -x[1])                     # top 2 customers\n",
        "# )\n",
        "# print(top2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Find the average order amount per city (join customers + orders).\n",
        "avg_ord=r2.map(lambda x:(x[1],int(x[3]))).join(r1.map(lambda x:(x[0],x[2]))).map(lambda x:(x[1][1],(x[1][0],1))).reduceByKey(lambda a,b:(a[0]+b[0],a[1]+b[1])).mapValues(lambda x:x[0]/x[1])\n",
        "print(avg_ord.collect())\n",
        "\n",
        "# Rank payment methods by total revenue generated.\n",
        "rank=r2.map(lambda x:(x[5],int(x[3]))).reduceByKey(lambda a,b:a+b).takeOrdered(10,key=lambda x:-x[1])\n",
        "for i,j in rank:\n",
        "  print(i,\"->\",j)\n",
        "# Find the customer with max and min order values.\n",
        "max_min=r1.map(lambda x:(x[0],x[1])).join(r2.map(lambda x:(x[1],int(x[3])))).map(lambda x:(x[1][0],x[1][1])).reduceByKey(lambda x,y:x+y)\n",
        "max=max_min.takeOrdered(1,key=lambda x:-x[1])\n",
        "min=max_min.takeOrdered(1,key=lambda x:x[1])\n",
        "print(max)\n",
        "print(min)\n",
        "\n",
        "# 2. Date & Time\n",
        "# Count how many orders were made per month.\n",
        "from datetime import datetime\n",
        "cnt = r2.map(lambda x: (datetime.strptime(x[4], \"%Y-%m-%d\").strftime(\"%b\"), 1)).reduceByKey(lambda a, b: a + b)\n",
        "print(cnt.collect())\n",
        "#OR\n",
        "cnt = r2.map(lambda x: (int(x[4].split(\"-\")[1]), 1)).reduceByKey(lambda a, b: a + b)\n",
        "print(cnt.collect())\n",
        "\n",
        "# Find the city with the earliest signup and the latest signup.\n",
        "ear_lat=r1.map(lambda x:(x[2],datetime.strptime(x[3],\"%Y-%m-%d\")))\n",
        "earliest_signup=ear_lat.takeOrdered(1,key=lambda x:x[1])\n",
        "latest_signup=ear_lat.takeOrdered(1,key=lambda x:-x[1].timestamp())\n",
        "print(earliest_signup)\n",
        "print(latest_signup)\n",
        "\n",
        "# Compare total signups per month vs total orders per month.\n",
        "signups_per_month=r1.map(lambda x:(datetime.strptime(x[3],\"%Y-%m-%d\").month,1)).reduceByKey(lambda x,y:x+y)\n",
        "order_per_month=r2.map(lambda x:(datetime.strptime(x[4],\"%Y-%m-%d\").month,1)).reduceByKey(lambda x,y:x+y)\n",
        "compare=signups_per_month.join(order_per_month)\n",
        "print(\"Month -> (Signups, Orders):\", compare.collect())\n",
        "\n",
        "# 3. String & Regex\n",
        "# Find all customers whose name starts with ‘R’.\n",
        "starts_r=r1.filter(lambda x:x[1].startswith(\"R\"))\n",
        "print(starts_r.collect())\n",
        "\n",
        "# Extract the year from signup_date and group customers by signup year.\n",
        "extract=r1.map(lambda x:(x[1],int(x[3].split(\"-\")[0]))).reduceByKey(lambda x,y:x+y)\n",
        "print(extract.collect())\n",
        "# Find all products whose name length > 6 characters.\n",
        "name_len=r3.filter(lambda x:len(x[1])>6).map(lambda x:x[1])\n",
        "print(name_len.collect())\n",
        "\n",
        "# Extract only numeric order IDs from orders dataset\n",
        "import re\n",
        "ex_num=r2.filter(lambda x:re.match(r\"^O[0-9]+$\",x[0])).map(lambda x:x[0])\n",
        "print(ex_num.collect())\n",
        "# Extract all order IDs that contain exactly 3 digits (like O123).\n",
        "ex_ord_3=r2.filter(lambda x:re.match(r\"^O[0-9]{3}\",x[0])).map(lambda x:x[0])\n",
        "print(ex_ord_3.collect())\n",
        "\n",
        "# Find all products in orders table whose payment method startswith \"C\" and endswith \"d\"\n",
        "ex_payment=r2.filter(lambda x:re.match(r\"^C.*d$\",x[5])).map(lambda x:(x[2],x[5]))\n",
        "print(ex_payment.collect())\n",
        "# OR\n",
        "ex_or=r2.filter(lambda x:(x[5].startswith(\"C\") and x[5].endswith(\"d\"))).map(lambda x:(x[2],x[5]))\n",
        "print(ex_payment.collect())\n",
        "\n",
        "# 4. Joins\n",
        "# Join customers and orders → list customer name, product, and amount.\n",
        "\n",
        "# Find total revenue per city (customers.city ↔ orders.amount).\n",
        "\n",
        "# Find all customers who have not placed any order.\n",
        "j10=r1.map(lambda x:(x[0],x[1])).leftOuterJoin(r2.map(lambda x:(x[1],1))).filter(lambda x:x[1][1] is None)\n",
        "print(j10.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYjBqfCB3HFG",
        "outputId": "0616fc11-038e-4e13-ab58-5c505a65f5cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Mumbai', 30000.0), ('Delhi', 36166.666666666664), ('Bangalore', 26066.666666666668)]\n",
            "Credit Card -> 78500\n",
            "Net Banking -> 60000\n",
            "UPI -> 46200\n",
            "Debit Card -> 30000\n",
            "COD -> 2000\n",
            "[('Raj', 76200)]\n",
            "[('Meera', 2000)]\n",
            "[('May', 7)]\n",
            "[(5, 7)]\n",
            "[('Bangalore', datetime.datetime(2023, 1, 12, 0, 0))]\n",
            "[('Delhi', datetime.datetime(2023, 4, 5, 0, 0))]\n",
            "Month -> (Signups, Orders): []\n",
            "[['C001', 'Raj', 'Bangalore', '2023-01-12'], ['C003', 'Rahul', 'Mumbai', '2023-03-15']]\n",
            "[('Raj', 2023), ('Ananya', 2023), ('Rahul', 2023), ('Meera', 2023), ('Sneha', 2023)]\n",
            "['Headphones', 'Keyboard']\n",
            "['O001', 'O002', 'O003', 'O004', 'O005', 'O006', 'O007']\n",
            "['O001', 'O002', 'O003', 'O004', 'O005', 'O006', 'O007']\n",
            "[('Laptop', 'Credit Card'), ('Keyboard', 'Credit Card')]\n",
            "[('Laptop', 'Credit Card'), ('Keyboard', 'Credit Card')]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # DATE AND TIME QUESTIONS ON DF AND SQL\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "spark = SparkSession.builder.appName(\"CSV Reader\").getOrCreate()\n",
        "df1=spark.read.csv(\"customers_rdd.csv\",inferSchema=True,header=True,sep=\",\").alias(\"c\")\n",
        "df2=spark.read.csv(\"orders_rdd.csv\",inferSchema=True,header=True,sep=\",\").alias(\"p\")\n",
        "df3=spark.read.csv(\"products_rdd.csv\",inferSchema=True,header=True,sep=\",\").alias(\"o\")\n",
        "df1.show()\n",
        "df2.show()\n",
        "df3.show()\n",
        "# # FROM DF\n",
        "# 1. Extract Year, Month, Day from order date\n",
        "ex_y=df2.select(date_format(\"order_date\",\"yyyy\").alias(\"order_year\")).show()\n",
        "ex_m=df2.select(month(col(\"order_date\")).alias(\"order_month\")).show()\n",
        "ex_d=df2.select(dayofmonth(col(\"order_date\")).alias(\"order_day\")).show()\n",
        "\n",
        "# 2. Find total orders per month\n",
        "total_orders_per_month=df2.select(date_format(\"order_date\",\"MMM\").alias(\"month\"),col(\"order_id\")).groupBy(\"month\").agg(count(col(\"order_id\")).alias(\"total_orders\")).orderBy(\"month\").show()\n",
        "from pyspark.sql.functions import avg\n",
        "\n",
        "# 3. Print rows whose amount is greater than the total average amount\n",
        "ex1 = df2.agg(avg(\"amount\").alias(\"average\")).collect()[0][\"average\"]\n",
        "print(ex1)\n",
        "\n",
        "# 4. Find the top 3 customers who spent the most in 2023.\n",
        "ex2=df2.filter(year(col(\"order_date\"))==2023).groupBy(col(\"cust_id\")).agg(sum(col(\"amount\")).alias(\"total_spent\")).orderBy(col(\"total_spent\").desc()).limit(3).show()\n",
        "\n",
        "# 5. Find the average order value for each payment method, only for products whose name length > 5.\n",
        "ex3=df2.select(col(\"amount\"),col(\"payment_method\"),col(\"product\")).filter(length(col(\"product\"))>5).groupBy(col(\"payment_method\")).agg(avg(col(\"amount\")).alias(\"avg_amount\")).show()\n",
        "\n",
        "# # FROM SQL\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "spark = SparkSession.builder.appName(\"CSV Reader\").getOrCreate()\n",
        "df1=spark.read.csv(\"customers_rdd.csv\",inferSchema=True,header=True,sep=\",\")\n",
        "df2=spark.read.csv(\"orders_rdd.csv\",inferSchema=True,header=True,sep=\",\")\n",
        "df3=spark.read.csv(\"products_rdd.csv\",inferSchema=True,header=True,sep=\",\")\n",
        "df1.createOrReplaceTempView(\"cust\")\n",
        "df2.createOrReplaceTempView(\"ord\")\n",
        "df3.createOrReplaceTempView(\"prod\")\n",
        "# 1. Extract Year, Month from orders\n",
        "spark.sql(\"select order_id,year(order_date) as year,month(order_date) as month from ord\").show()\n",
        "\n",
        "# 2.Find the earliest and latest signup date per city\n",
        "spark.sql(\"select max(signup_date) as latest_signup_date,min(signup_date) as earliest_signup_date from cust\").show()\n",
        "\n",
        "# 3.Monthly total sales\n",
        "spark.sql(\"select date_format(order_date,'yyyy-MM') as month ,sum(amount) as total_amount from ord group by month order by month\").show()\n",
        "\n",
        "spark.sql(\"select * from ord where amount > (select avg(amount) as average from ord)\").show()\n",
        "\n",
        "# 4. Find the average order value for each payment method, only for products whose name length > 5.\n",
        "spark.sql(\"select avg(amount) as avg_amount,payment_method from ord where length(product)>5 group by payment_method\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FumvdHycR7Ei",
        "outputId": "a93f6d07-d1bd-4b4c-a336-18ef9685f619"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+---------+-----------+\n",
            "|cust_id|  name|     city|signup_date|\n",
            "+-------+------+---------+-----------+\n",
            "|   C001|   Raj|Bangalore| 2023-01-12|\n",
            "|   C002|Ananya|    Delhi| 2023-02-20|\n",
            "|   C003| Rahul|   Mumbai| 2023-03-15|\n",
            "|   C004| Meera|Bangalore| 2023-03-18|\n",
            "|   C005| Sneha|    Delhi| 2023-04-05|\n",
            "+-------+------+---------+-----------+\n",
            "\n",
            "+--------+-------+----------+------+----------+--------------+\n",
            "|order_id|cust_id|   product|amount|order_date|payment_method|\n",
            "+--------+-------+----------+------+----------+--------------+\n",
            "|    O001|   C001|    Laptop| 75000|2023-05-10|   Credit Card|\n",
            "|    O002|   C002|     Phone| 45000|2023-05-12|           UPI|\n",
            "|    O003|   C003|    Tablet| 30000|2023-05-13|    Debit Card|\n",
            "|    O004|   C004|Headphones|  2000|2023-05-15|           COD|\n",
            "|    O005|   C001|     Mouse|  1200|2023-05-16|           UPI|\n",
            "|    O006|   C002|  Keyboard|  3500|2023-05-20|   Credit Card|\n",
            "|    O007|   C005|    Laptop| 60000|2023-05-25|   Net Banking|\n",
            "+--------+-------+----------+------+----------+--------------+\n",
            "\n",
            "+----------+------------+-----------+-----+--------+\n",
            "|product_id|product_name|   category|price|  vendor|\n",
            "+----------+------------+-----------+-----+--------+\n",
            "|      P001|      Laptop|Electronics|75000|    Dell|\n",
            "|      P002|       Phone|Electronics|45000| Samsung|\n",
            "|      P003|      Tablet|Electronics|30000|   Apple|\n",
            "|      P004|  Headphones|Accessories| 2000|    Boat|\n",
            "|      P005|       Mouse|Accessories| 1200|Logitech|\n",
            "|      P006|    Keyboard|Accessories| 3500|      HP|\n",
            "+----------+------------+-----------+-----+--------+\n",
            "\n",
            "+----------+\n",
            "|order_year|\n",
            "+----------+\n",
            "|      2023|\n",
            "|      2023|\n",
            "|      2023|\n",
            "|      2023|\n",
            "|      2023|\n",
            "|      2023|\n",
            "|      2023|\n",
            "+----------+\n",
            "\n",
            "+-----------+\n",
            "|order_month|\n",
            "+-----------+\n",
            "|          5|\n",
            "|          5|\n",
            "|          5|\n",
            "|          5|\n",
            "|          5|\n",
            "|          5|\n",
            "|          5|\n",
            "+-----------+\n",
            "\n",
            "+---------+\n",
            "|order_day|\n",
            "+---------+\n",
            "|       10|\n",
            "|       12|\n",
            "|       13|\n",
            "|       15|\n",
            "|       16|\n",
            "|       20|\n",
            "|       25|\n",
            "+---------+\n",
            "\n",
            "+-----+------------+\n",
            "|month|total_orders|\n",
            "+-----+------------+\n",
            "|  May|           7|\n",
            "+-----+------------+\n",
            "\n",
            "30957.14285714286\n",
            "+-------+-----------+\n",
            "|cust_id|total_spent|\n",
            "+-------+-----------+\n",
            "|   C001|      76200|\n",
            "|   C005|      60000|\n",
            "|   C002|      48500|\n",
            "+-------+-----------+\n",
            "\n",
            "+--------------+----------+\n",
            "|payment_method|avg_amount|\n",
            "+--------------+----------+\n",
            "|           COD|    2000.0|\n",
            "|   Credit Card|   39250.0|\n",
            "|   Net Banking|   60000.0|\n",
            "|    Debit Card|   30000.0|\n",
            "+--------------+----------+\n",
            "\n",
            "+--------+----+-----+\n",
            "|order_id|year|month|\n",
            "+--------+----+-----+\n",
            "|    O001|2023|    5|\n",
            "|    O002|2023|    5|\n",
            "|    O003|2023|    5|\n",
            "|    O004|2023|    5|\n",
            "|    O005|2023|    5|\n",
            "|    O006|2023|    5|\n",
            "|    O007|2023|    5|\n",
            "+--------+----+-----+\n",
            "\n",
            "+------------------+--------------------+\n",
            "|latest_signup_date|earliest_signup_date|\n",
            "+------------------+--------------------+\n",
            "|        2023-04-05|          2023-01-12|\n",
            "+------------------+--------------------+\n",
            "\n",
            "+-------+------------+\n",
            "|  month|total_amount|\n",
            "+-------+------------+\n",
            "|2023-05|      216700|\n",
            "+-------+------------+\n",
            "\n",
            "+--------+-------+-------+------+----------+--------------+\n",
            "|order_id|cust_id|product|amount|order_date|payment_method|\n",
            "+--------+-------+-------+------+----------+--------------+\n",
            "|    O001|   C001| Laptop| 75000|2023-05-10|   Credit Card|\n",
            "|    O002|   C002|  Phone| 45000|2023-05-12|           UPI|\n",
            "|    O007|   C005| Laptop| 60000|2023-05-25|   Net Banking|\n",
            "+--------+-------+-------+------+----------+--------------+\n",
            "\n",
            "+----------+--------------+\n",
            "|avg_amount|payment_method|\n",
            "+----------+--------------+\n",
            "|    2000.0|           COD|\n",
            "|   39250.0|   Credit Card|\n",
            "|   60000.0|   Net Banking|\n",
            "|   30000.0|    Debit Card|\n",
            "+----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 RDD Questions (2 with concat idea)\n",
        "# Concatenate cust_id and order_id in orders to create a unique transaction_key RDD.\n",
        "concat_1=r2.map(lambda x:(x[1]+'_'+x[0]))\n",
        "print(concat_1.collect())\n",
        "\n",
        "concat_2=r2.map(lambda x:(x[2]+\"->\"+x[3]))\n",
        "print(concat_2.collect())\n",
        "# 🔹 DataFrame Questions (4 with between, isin, like, rlike)\n",
        "# Find all orders where amount is between 1000 and 5000.\n",
        "df2.filter(col(\"amount\").between(1000,5000)).show()\n",
        "# Find all customers who live in either \"Delhi\" or \"Bangalore\".\n",
        "df1.filter(col(\"city\").isin([\"Delhi\",\"Bangalore\"])).show()\n",
        "\n",
        "# Find all customers whose name starts with \"R\".\n",
        "df1.filter(col(\"name\").rlike(\"j$\")).show()\n",
        "df1.filter(col(\"name\").endswith(\"j\")).show()\n",
        "df1.filter(col(\"name\").like(\"%j\")).show()\n",
        "\n",
        "# Find all payment methods that end with \"Card\" using regex.\n",
        "df2.filter(col(\"payment_method\").endswith(\"Card\")).show()\n",
        "\n",
        "# 🔹 SQL Questions (4 with regex, between, in, like)\n",
        "# Find all orders where amount is between 1000 and 5000.\n",
        "spark.sql(\"select * from ord where amount between 1000 and 5000\").show()\n",
        "# Find all customers who live in \"Delhi\" or \"Bangalore\".\n",
        "spark.sql(\"select * from cust where city in ('Delhi','Bangalore')\").show()\n",
        "\n",
        "# Find all customers whose name starts with \"R\".\n",
        "spark.sql(\"select * from cust where name like('R%')\").show()\n",
        "# Find all orders where payment_method ends with \"Card\" using regex (RLIKE).\n",
        "spark.sql(\"select * from ord where payment_method like('%Card')\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3mANyHKk_VA",
        "outputId": "c12f89a8-264a-4ddc-bc71-245447109789"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['C001_O001', 'C002_O002', 'C003_O003', 'C004_O004', 'C001_O005', 'C002_O006', 'C005_O007']\n",
            "['Laptop->75000', 'Phone->45000', 'Tablet->30000', 'Headphones->2000', 'Mouse->1200', 'Keyboard->3500', 'Laptop->60000']\n",
            "+--------+-------+----------+------+----------+--------------+\n",
            "|order_id|cust_id|   product|amount|order_date|payment_method|\n",
            "+--------+-------+----------+------+----------+--------------+\n",
            "|    O004|   C004|Headphones|  2000|2023-05-15|           COD|\n",
            "|    O005|   C001|     Mouse|  1200|2023-05-16|           UPI|\n",
            "|    O006|   C002|  Keyboard|  3500|2023-05-20|   Credit Card|\n",
            "+--------+-------+----------+------+----------+--------------+\n",
            "\n",
            "+-------+------+---------+-----------+\n",
            "|cust_id|  name|     city|signup_date|\n",
            "+-------+------+---------+-----------+\n",
            "|   C001|   Raj|Bangalore| 2023-01-12|\n",
            "|   C002|Ananya|    Delhi| 2023-02-20|\n",
            "|   C004| Meera|Bangalore| 2023-03-18|\n",
            "|   C005| Sneha|    Delhi| 2023-04-05|\n",
            "+-------+------+---------+-----------+\n",
            "\n",
            "+-------+----+---------+-----------+\n",
            "|cust_id|name|     city|signup_date|\n",
            "+-------+----+---------+-----------+\n",
            "|   C001| Raj|Bangalore| 2023-01-12|\n",
            "+-------+----+---------+-----------+\n",
            "\n",
            "+-------+----+---------+-----------+\n",
            "|cust_id|name|     city|signup_date|\n",
            "+-------+----+---------+-----------+\n",
            "|   C001| Raj|Bangalore| 2023-01-12|\n",
            "+-------+----+---------+-----------+\n",
            "\n",
            "+-------+----+---------+-----------+\n",
            "|cust_id|name|     city|signup_date|\n",
            "+-------+----+---------+-----------+\n",
            "|   C001| Raj|Bangalore| 2023-01-12|\n",
            "+-------+----+---------+-----------+\n",
            "\n",
            "+--------+-------+--------+------+----------+--------------+\n",
            "|order_id|cust_id| product|amount|order_date|payment_method|\n",
            "+--------+-------+--------+------+----------+--------------+\n",
            "|    O001|   C001|  Laptop| 75000|2023-05-10|   Credit Card|\n",
            "|    O003|   C003|  Tablet| 30000|2023-05-13|    Debit Card|\n",
            "|    O006|   C002|Keyboard|  3500|2023-05-20|   Credit Card|\n",
            "+--------+-------+--------+------+----------+--------------+\n",
            "\n",
            "+--------+-------+----------+------+----------+--------------+\n",
            "|order_id|cust_id|   product|amount|order_date|payment_method|\n",
            "+--------+-------+----------+------+----------+--------------+\n",
            "|    O004|   C004|Headphones|  2000|2023-05-15|           COD|\n",
            "|    O005|   C001|     Mouse|  1200|2023-05-16|           UPI|\n",
            "|    O006|   C002|  Keyboard|  3500|2023-05-20|   Credit Card|\n",
            "+--------+-------+----------+------+----------+--------------+\n",
            "\n",
            "+-------+------+---------+-----------+\n",
            "|cust_id|  name|     city|signup_date|\n",
            "+-------+------+---------+-----------+\n",
            "|   C001|   Raj|Bangalore| 2023-01-12|\n",
            "|   C002|Ananya|    Delhi| 2023-02-20|\n",
            "|   C004| Meera|Bangalore| 2023-03-18|\n",
            "|   C005| Sneha|    Delhi| 2023-04-05|\n",
            "+-------+------+---------+-----------+\n",
            "\n",
            "+-------+-----+---------+-----------+\n",
            "|cust_id| name|     city|signup_date|\n",
            "+-------+-----+---------+-----------+\n",
            "|   C001|  Raj|Bangalore| 2023-01-12|\n",
            "|   C003|Rahul|   Mumbai| 2023-03-15|\n",
            "+-------+-----+---------+-----------+\n",
            "\n",
            "+--------+-------+--------+------+----------+--------------+\n",
            "|order_id|cust_id| product|amount|order_date|payment_method|\n",
            "+--------+-------+--------+------+----------+--------------+\n",
            "|    O001|   C001|  Laptop| 75000|2023-05-10|   Credit Card|\n",
            "|    O003|   C003|  Tablet| 30000|2023-05-13|    Debit Card|\n",
            "|    O006|   C002|Keyboard|  3500|2023-05-20|   Credit Card|\n",
            "+--------+-------+--------+------+----------+--------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}